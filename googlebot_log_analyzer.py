import streamlit as st
import gzip
import re
import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt

# Bilinen botlar
KNOWN_BOTS = {
    'Googlebot': re.compile(r'Googlebot', re.I),
    'Bingbot': re.compile(r'Bingbot', re.I),
    'YandexBot': re.compile(r'YandexBot', re.I),
    'AhrefsBot': re.compile(r'AhrefsBot', re.I),
    'SemrushBot': re.compile(r'SemrushBot', re.I),
    'Baiduspider': re.compile(r'Baiduspider', re.I),
    'MJ12bot': re.compile(r'MJ12bot', re.I),
}

def detect_bot(user_agent):
    for bot_name, pattern in KNOWN_BOTS.items():
        if pattern.search(user_agent):
            return bot_name
    return 'Other'

# Nginx/Apache combined log format regex parser
log_pattern = re.compile(
    r'(?P<ip>\d+\.\d+\.\d+\.\d+) - - \[(?P<datetime>[^\]]+)\] '
    r'"(?P<method>\S+) (?P<url>\S+) \S+" '
    r'(?P<status>\d{3}) \d+ "-" "(?P<user_agent>[^"]+)"'
)

def parse_log_line(line):
    m = log_pattern.match(line)
    if not m:
        return None
    ip = m.group('ip')
    dt_str = m.group('datetime')
    url = m.group('url')
    status = int(m.group('status'))
    user_agent = m.group('user_agent')

    # Tarihi datetime objesine Ã§evir
    try:
        dt = datetime.strptime(dt_str, "%d/%b/%Y:%H:%M:%S %z")
    except:
        return None

    bot = detect_bot(user_agent)

    return {
        'IP': ip,
        'URL': url,
        'Status': status,
        'Datetime': dt,
        'User-Agent': user_agent,
        'Bot': bot
    }

def load_log_file(file) -> pd.DataFrame:
    """
    .gz veya dÃ¼z metin dosya olabilir
    """
    if file.name.endswith('.gz'):
        with gzip.open(file, 'rt', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
    else:
        # .txt dosyasÄ± ise
        # streamlit file_uploader'dan gelen dosya bytes olabilir,
        # Ã¶nce decode etmeliyiz
        content = file.getvalue()
        if isinstance(content, bytes):
            content = content.decode('utf-8', errors='ignore')
        lines = content.splitlines()

    records = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        parsed = parse_log_line(line)
        if parsed:
            records.append(parsed)

    df = pd.DataFrame(records)
    return df

def main():
    st.title("ðŸš€ GeliÅŸmiÅŸ Bot & SEO Log AnalizÃ¶rÃ¼")
    st.markdown("""
    **Nginx/Apache eriÅŸim log dosyanÄ±zÄ± yÃ¼kleyin (txt veya gz).**  
    Bot ziyaretlerini, HTTP durum kodlarÄ±nÄ± ve SEO hatalarÄ±nÄ± analiz edin.
    """)

    uploaded_file = st.file_uploader("Log dosyanÄ±zÄ± seÃ§in (txt, gz)", type=['txt', 'gz'])
    if uploaded_file:
        try:
            df = load_log_file(uploaded_file)
        except Exception as e:
            st.error(f"Dosya okunurken hata oluÅŸtu: {e}")
            return

        if df.empty:
            st.warning("YÃ¼klenen dosyada geÃ§erli log verisi bulunamadÄ± veya format uyumsuz.")
            return

        st.success(f"Log dosyasÄ± baÅŸarÄ±yla yÃ¼klendi! Toplam {len(df)} kayÄ±t.")

        # Genel Ã¶zet
        st.subheader("ðŸ“‹ Genel Ã–zet")
        st.write(f"Toplam KayÄ±t: {len(df)}")
        st.write(f"Tarayan Bot TÃ¼rÃ¼ SayÄ±sÄ±: {df['Bot'].nunique()}")
        st.write("En Ã‡ok Tarayan Botlar:")
        st.bar_chart(df['Bot'].value_counts())

        # Bot seÃ§imi
        st.subheader("ðŸ”Ž Botlara GÃ¶re Filtreleme")
        bots = ['All'] + sorted(df['Bot'].unique().tolist())
        selected_bot = st.selectbox("Bot SeÃ§in:", bots)
        if selected_bot != 'All':
            df = df[df['Bot'] == selected_bot]

        # Durum kodu filtreleme
        st.subheader("ðŸ›‘ HTTP Durum KodlarÄ±na GÃ¶re Filtreleme")
        status_codes = sorted(df['Status'].unique().tolist())
        selected_status = st.multiselect("Durum KodlarÄ±nÄ± SeÃ§in:", options=status_codes, default=status_codes)
        df = df[df['Status'].isin(selected_status)]

        # Tarih aralÄ±ÄŸÄ±
        st.subheader("ðŸ“… Tarih AralÄ±ÄŸÄ± SeÃ§imi")
        min_date = df['Datetime'].min().date()
        max_date = df['Datetime'].max().date()
        selected_date = st.date_input("Tarih AralÄ±ÄŸÄ±:", value=(min_date, max_date))
        if isinstance(selected_date, tuple) and len(selected_date) == 2:
            start, end = selected_date
            df = df[(df['Datetime'].dt.date >= start) & (df['Datetime'].dt.date <= end)]

        # FiltrelenmiÅŸ tablo
        st.subheader(f"ðŸ“Š FiltrelenmiÅŸ KayÄ±tlar ({len(df)})")
        st.dataframe(df[['Datetime', 'IP', 'URL', 'Status', 'Bot']].sort_values(by='Datetime', ascending=False))

        # SEO hata raporu
        st.subheader("ðŸš¨ SEO Hata Raporu")
        st.markdown("**En Ã§ok 404 (Sayfa BulunamadÄ±) hatasÄ± olan URL'ler:**")
        errors_404 = df[df['Status'] == 404]
        top_404 = errors_404['URL'].value_counts().head(10)
        if not top_404.empty:
            st.table(top_404)
        else:
            st.write("404 hatasÄ± bulunamadÄ±.")

        st.markdown("**En Ã§ok 301 (YÃ¶nlendirme) durumu olan URL'ler:**")
        redirects_301 = df[df['Status'] == 301]
        top_301 = redirects_301['URL'].value_counts().head(10)
        if not top_301.empty:
            st.table(top_301)
        else:
            st.write("301 yÃ¶nlendirme durumu bulunamadÄ±.")

        # GÃ¼nlÃ¼k yoÄŸunluk grafiÄŸi
        st.subheader("ðŸ“ˆ GÃ¼nlÃ¼k Tarama YoÄŸunluÄŸu (SeÃ§ilen Filtreye GÃ¶re)")
        daily_counts = df.groupby(df['Datetime'].dt.date).size()
        fig, ax = plt.subplots()
        daily_counts.plot(kind='bar', ax=ax, figsize=(10,4))
        ax.set_xlabel("Tarih")
        ax.set_ylabel("Ziyaret SayÄ±sÄ±")
        ax.set_title("GÃ¼nlÃ¼k Bot Ziyaretleri")
        st.pyplot(fig)

if __name__ == "__main__":
    main()
